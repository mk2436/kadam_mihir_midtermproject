{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31fb5677"
      },
      "source": [
        "# Data Mining : Midterm Project\n",
        "\n",
        "Name: <b>Mihir Kadam</b><br>\n",
        "Ucid: mk2436<br>\n",
        "Email Id: mk2436@njit.edu<br>\n",
        "<br>\n",
        "Submitted to: <b>Dr. Yasser Abduallah</b><br>\n",
        "<br>\n",
        "\n",
        "### Description\n",
        "\n",
        "This notebook implements and compares three frequent itemset mining algorithms: **Brute Force**, **Apriori**, and **FP-Growth**. It allows users to load transaction data from CSV files, set minimum support and confidence thresholds, and analyze the performance and results of each algorithm in finding frequent itemsets and generating association rules.\n",
        "\n",
        "### Algorithms Implemented\n",
        "\n",
        "- **Brute Force**: A naive approach that checks all possible item combinations.\n",
        "- **Apriori**: A classic algorithm that uses the anti-monotonic property of support to efficiently find frequent itemsets.\n",
        "- **FP-Growth**: An algorithm that uses a frequent pattern tree (FP-tree) to mine frequent itemsets without generating candidate itemsets.\n",
        "\n",
        "\n",
        "### Usage\n",
        "\n",
        "1. Upload your transaction and itemset CSV files to the Colab environment. Example files are provided for several stores (Amazon, Bestbuy, Shoprite, K-mart, Nike).\n",
        "2. Run all the code cells.\n",
        "3. When prompted, select the store you want to analyze by entering its corresponding number.\n",
        "4. Enter the minimum support and confidence thresholds as percentages (between 1 and 100).\n",
        "5. The notebook will then run each algorithm, display the frequent itemsets and association rules found, and show the execution time for each.\n",
        "6. Finally, it will identify and print the fastest algorithm based on execution time.\n",
        "\n",
        "### Data Format\n",
        "\n",
        "- **Transaction File**: A CSV file where each row represents a transaction. Items within a transaction can be in separate columns or comma-separated within a single cell.\n",
        "- **Itemset File**: A CSV file with at least two columns: 'Item #' (item ID) and 'Item Name' (item name). This file is used to map item IDs to names if available.\n",
        "\n",
        "### Dependencies\n",
        "\n",
        "- pandas\n",
        "- mlxtend\n",
        "- tabulate\n",
        "\n",
        "Install dependencies using pip if necessary:\n",
        "`!pip install pandas mlxtend tabulate`\n",
        "\n",
        "### Notes\n",
        "\n",
        "- The Brute Force algorithm can be very slow for large datasets due to its exhaustive search approach.\n",
        "- Apriori and FP-Growth algorithms are more efficient for larger datasets.\n",
        "- The results are printed in a tabular format for easy comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeVgZaGQYLaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04cb6f28-8a64-4de0-e49e-291a155cde31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "# If you see the warning:\n",
        "# \"DeprecationWarning: datetime.datetime.utcnow() is deprecated ...\"\n",
        "# run this cell before executing any other code to prevent the warning\n",
        "# from breaking your notebook.\n",
        "\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=DeprecationWarning,\n",
        "    message=r\"datetime\\.datetime\\.utcnow\\(\\).*deprecated\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9M9h0-epXR84"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import time\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b1f141d"
      },
      "source": [
        "### How `calculate_support` works:\n",
        "\n",
        "This function helps us understand how popular a specific group of items (an 'itemset') is by looking at all the customer transactions. It figures out what percentage of all transactions include every single item in the itemset you're interested in.\n",
        "\n",
        "Think of it like this: If you want to know the support for 'milk and bread', this function counts how many transactions have *both* milk and bread, and then divides that by the total number of transactions. The result, a number between 0 and 1, tells you how frequently 'milk and bread' appear together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHPaQ57DXaf2"
      },
      "outputs": [],
      "source": [
        "def calculate_support(itemset, transactions):\n",
        "    \"\"\"\n",
        "    Return the fraction of transactions containing the itemset.\n",
        "\n",
        "    Args:\n",
        "        itemset (tuple or list): Items to check.\n",
        "        transactions (list of lists): List of transactions.\n",
        "\n",
        "    Returns:\n",
        "        float: Support value (0 to 1).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return sum(1 for t in transactions if set(itemset).issubset(set(t))) / len(transactions)\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating support \\n{e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32e2fbd7"
      },
      "source": [
        "### How `prepare_transaction_dataframe` works:\n",
        "\n",
        "This function takes your list of customer transactions and turns it into a format that's easy for algorithms like Apriori and FP-Growth to understand. It creates a table (a pandas DataFrame) where:\n",
        "\n",
        "- Each row represents a single transaction.\n",
        "- Each column represents a unique item found across all transactions.\n",
        "\n",
        "For each cell in this table, it simply puts a `True` if the item in that column was present in the transaction for that row, and `False` otherwise. This \"one-hot encoding\" makes it straightforward for itemset mining algorithms to quickly see which items appear together in transactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu7qPto1X-iY"
      },
      "outputs": [],
      "source": [
        "def prepare_transaction_dataframe(transactions):\n",
        "    \"\"\"\n",
        "    Convert a list of transactions into a one-hot encoded pandas DataFrame.\n",
        "\n",
        "    Each column represents an item, and each row represents a transaction.\n",
        "    True indicates the item is present in the transaction; False otherwise.\n",
        "\n",
        "    Args:\n",
        "        transactions (list of lists): List of transactions, where each transaction is a list of items.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: One-hot encoded DataFrame of shape (num_transactions, num_items).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        items = sorted(set(i for t in transactions for i in t))\n",
        "        df = pd.DataFrame([[i in t for i in items] for t in transactions], columns=items).astype(bool)\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataframe \\n{e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51d0df75"
      },
      "source": [
        "### How `load_transaction_data` works:\n",
        "\n",
        "This function is responsible for reading your raw transaction and item information from CSV files. It does two main things:\n",
        "\n",
        "1.  **Reads Transactions:** It opens the transaction CSV and goes through each row. It expects items within a row to be either in separate columns or separated by commas. It collects all the items from each valid row to form a list of transactions.\n",
        "2.  **Creates Item Map (if available):** If you provide an itemset CSV with 'Item #' and 'Item Name' columns, this function creates a dictionary that links the item's ID (number) to its actual name. This is helpful for displaying results with understandable item names instead of just numbers.\n",
        "\n",
        "Essentially, it prepares your raw data into a structured format (a list of transactions and an optional item name map) that the other functions in the notebook can then process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rwh3BUsajWB"
      },
      "outputs": [],
      "source": [
        "def load_transaction_data(transaction_file, itemset_file):\n",
        "    \"\"\"\n",
        "    Load transaction and itemset data from CSV files.\n",
        "\n",
        "    Reads a transaction CSV file and an itemset CSV file. Processes the transactions\n",
        "    into a list of lists, where each inner list represents a single transaction. If the\n",
        "    itemset file contains 'Item #' and 'Item Name' columns, a mapping dictionary is created.\n",
        "\n",
        "    Args:\n",
        "        transaction_file (str): Path to the CSV file containing transaction data.\n",
        "        itemset_file (str): Path to the CSV file containing item ID and item name mapping.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - transactions (list of lists): Each inner list represents a transaction with item names as strings.\n",
        "            - item_map (dict or None): Mapping from item IDs to item names if available, otherwise None.\n",
        "\n",
        "    Notes:\n",
        "        - Items in transaction rows can be comma-separated strings or numeric values.\n",
        "        - Empty or invalid transactions are ignored.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df_trans = pd.read_csv(transaction_file)\n",
        "        df_items = pd.read_csv(itemset_file)\n",
        "\n",
        "        if 'Item #' in df_items.columns and 'Item Name' in df_items.columns:\n",
        "            item_map = dict(zip(df_items['Item #'], df_items['Item Name']))\n",
        "        else:\n",
        "            item_map = None\n",
        "\n",
        "        transactions = []\n",
        "        for _, row in df_trans.iterrows():\n",
        "            transaction = []\n",
        "            for item in row:\n",
        "                if isinstance(item, str):\n",
        "                    items = [i.strip() for i in item.split(',') if i.strip()]\n",
        "                    transaction.extend(items)\n",
        "                elif pd.notna(item):\n",
        "                    transaction.append(str(item))\n",
        "            if transaction:\n",
        "                transactions.append(transaction)\n",
        "        return transactions, item_map\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSVs \\n{e}\")\n",
        "        return None, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "002a59d3"
      },
      "source": [
        "### How `brute_force_algorithm` works:\n",
        "\n",
        "This function implements the Brute Force approach to find frequent itemsets and association rules. It works by:\n",
        "\n",
        "1.  **Generating Candidates:** It creates every possible combination of items from the transactions, starting with single items and going up to combinations of all items.\n",
        "2.  **Calculating Support:** For each combination (itemset), it checks how many transactions contain all the items in that set and calculates the support (the percentage of transactions containing the itemset).\n",
        "3.  **Filtering Frequent Itemsets:** It keeps only those itemsets whose support is equal to or greater than the minimum support threshold you specified.\n",
        "4.  **Generating Association Rules:** From the frequent itemsets, it creates possible association rules (e.g., \"if a customer buys A, they also buy B\").\n",
        "5.  **Calculating Confidence:** For each rule, it calculates the confidence (how often itemset B appears in transactions that already contain itemset A).\n",
        "6.  **Filtering Rules:** It keeps only those rules whose confidence is equal to or greater than the minimum confidence threshold you specified.\n",
        "\n",
        "Because it checks every single possible combination, this method can be very slow for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hxw8ALYYj-5"
      },
      "outputs": [],
      "source": [
        "def brute_force_algorithm(transactions, min_support, min_confidence):\n",
        "    \"\"\"\n",
        "    Run the Brute Force algorithm to find frequent itemsets and generate association rules.\n",
        "\n",
        "    This function exhaustively generates all possible item combinations from the transactions,\n",
        "    calculates their support, and retains those meeting the minimum support threshold.\n",
        "    It then generates association rules from frequent itemsets, keeping only those with\n",
        "    confidence above the specified threshold.\n",
        "\n",
        "    Args:\n",
        "        transactions (list of lists): A list where each inner list represents a transaction containing items as strings.\n",
        "        min_support (float): Minimum support threshold (0 <= min_support <= 1) for an itemset to be considered frequent.\n",
        "        min_confidence (float): Minimum confidence threshold (0 <= min_confidence <= 1) for association rules.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - frequent_itemsets (list of tuples): Each tuple contains (itemset, support) for itemsets meeting the min_support.\n",
        "            - rules (list of tuples): Each tuple contains (antecedent, consequent, confidence, support) for rules meeting min_confidence.\n",
        "            - runtime (float): Execution time in seconds for the algorithm.\n",
        "\n",
        "    Notes:\n",
        "        - This is a computationally expensive method for large datasets, as it checks all possible item combinations.\n",
        "        - If no frequent itemsets are found, returns (None, None, runtime).\n",
        "        - The function prints results in a tabular format using `print_results`.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nRunning Brute Force Algorithm...\")\n",
        "    start = time.time()\n",
        "    try:\n",
        "        items = sorted(set(i for t in transactions for i in t))\n",
        "        frequent_itemsets = []\n",
        "        size = 1\n",
        "\n",
        "        while True:\n",
        "            candidates = list(itertools.combinations(items, size))\n",
        "            current = []\n",
        "            for itemset in candidates:\n",
        "                support = calculate_support(itemset, transactions)\n",
        "                if support >= min_support:\n",
        "                    current.append((itemset, support))\n",
        "            if not current:\n",
        "                break\n",
        "            frequent_itemsets.extend(current)\n",
        "            size += 1\n",
        "\n",
        "        # Generate rules\n",
        "        rules = []\n",
        "        for itemset, support in frequent_itemsets:\n",
        "            if len(itemset) > 1:\n",
        "                for i in range(1, len(itemset)):\n",
        "                    for antecedent in itertools.combinations(itemset, i):\n",
        "                        consequent = tuple(x for x in itemset if x not in antecedent)\n",
        "                        antecedent_support = calculate_support(antecedent, transactions)\n",
        "                        confidence = support / antecedent_support\n",
        "                        if confidence >= min_confidence:\n",
        "                            rules.append((antecedent, consequent, confidence, support))\n",
        "    except Exception as e:\n",
        "        print(f\"Error running Brute Force \\n{e}\")\n",
        "\n",
        "    finally:\n",
        "        runtime = time.time() - start\n",
        "\n",
        "    if not frequent_itemsets:\n",
        "        print(\"No frequent itemsets found with Brute Force.\")\n",
        "        return None, None, runtime\n",
        "\n",
        "    print(f\"Brute Force completed in {runtime:.4f} seconds.\\n\")\n",
        "    print_results(\"Brute Force\", frequent_itemsets, rules)\n",
        "    return frequent_itemsets, rules, runtime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b049538"
      },
      "source": [
        "### How `apriori_algorithm` works:\n",
        "\n",
        "This function implements the Apriori algorithm using the `mlxtend` library. It's a more efficient method than Brute Force because it uses a key property: if an itemset is frequent, all of its subsets must also be frequent. This helps prune the search space significantly. The function does the following:\n",
        "\n",
        "1.  **Find Frequent Itemsets:** It uses the `mlxtend.apriori` function on the prepared transaction data to find all itemsets whose support meets the minimum threshold you provide. It does this by iteratively building larger frequent itemsets from smaller ones.\n",
        "2.  **Generate Association Rules:** From the frequent itemsets found, it generates possible association rules (e.g., \"if a customer buys A, they also buy B\") using the `mlxtend.association_rules` function.\n",
        "3.  **Filter Rules by Confidence:** It keeps only those rules whose confidence (how often the consequent items are purchased when the antecedent items are purchased) is at or above the minimum confidence threshold you specified.\n",
        "\n",
        "This approach is generally much faster than Brute Force, especially for larger datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPO4jG_RYs5W"
      },
      "outputs": [],
      "source": [
        "def apriori_algorithm(transaction_df, min_support, min_confidence):\n",
        "    \"\"\"\n",
        "    Run the Apriori algorithm using mlxtend to find frequent itemsets and generate association rules.\n",
        "\n",
        "    This function uses the Apriori algorithm on a one-hot encoded DataFrame of transactions to\n",
        "    identify frequent itemsets that meet the minimum support threshold. It then generates\n",
        "    association rules from these itemsets that meet the minimum confidence threshold.\n",
        "\n",
        "    Args:\n",
        "        transaction_df (pd.DataFrame): One-hot encoded DataFrame where each column is an item and\n",
        "                                       each row represents a transaction (True if item present).\n",
        "        min_support (float): Minimum support threshold (0 <= min_support <= 1) for an itemset to be considered frequent.\n",
        "        min_confidence (float): Minimum confidence threshold (0 <= min_confidence <= 1) for association rules.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - frequent_itemsets (pd.DataFrame or None): DataFrame of frequent itemsets with support values.\n",
        "                                                        None if no frequent itemsets are found.\n",
        "            - rules (pd.DataFrame or None): DataFrame of association rules with confidence and support.\n",
        "                                            None if no rules meet the threshold.\n",
        "            - runtime (float): Execution time in seconds for the algorithm.\n",
        "\n",
        "    Notes:\n",
        "        - Uses mlxtend.apriori for frequent itemset mining and mlxtend.association_rules for rule generation.\n",
        "        - If no frequent itemsets are found, returns (None, None, runtime).\n",
        "        - The function prints results in a tabular format using `print_results`.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nRunning Apriori Algorithm...\")\n",
        "    frequent_itemsets = None\n",
        "    start = time.time()\n",
        "\n",
        "    try:\n",
        "        frequent_itemsets = apriori(transaction_df, min_support=min_support, use_colnames=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error running Arpiori \\n{e}\")\n",
        "\n",
        "    finally:\n",
        "        runtime = time.time() - start\n",
        "\n",
        "    if frequent_itemsets.empty:\n",
        "        print(\"No frequent itemsets found with Apriori.\")\n",
        "        return None, None, runtime\n",
        "\n",
        "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
        "    print(f\"Apriori completed in {runtime:.4f} seconds.\\n\")\n",
        "    print_results(\"Apriori\", frequent_itemsets, rules)\n",
        "    return frequent_itemsets, rules, runtime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f47eaaba"
      },
      "source": [
        "### How `fpgrowth_algorithm` works:\n",
        "\n",
        "This function applies the FP-Growth algorithm on a one-hot encoded DataFrame of transactions\n",
        "to identify frequent itemsets that meet the minimum support threshold. It then generates\n",
        "association rules from these itemsets that meet the minimum confidence threshold.\n",
        "\n",
        "Args:\n",
        "transaction_df (pd.DataFrame): One-hot encoded DataFrame where each column is an item and\n",
        "each row represents a transaction (True if item present).\n",
        "min_support (float): Minimum support threshold (0 <= min_support <= 1) for an itemset to be considered frequent.\n",
        "min_confidence (float): Minimum confidence threshold (0 <= min_confidence <= 1) for association rules.\n",
        "\n",
        "Returns:\n",
        "tuple:\n",
        "- frequent_itemsets (pd.DataFrame or None): DataFrame of frequent itemsets with support values.\n",
        "None if no frequent itemsets are found.\n",
        "- rules (pd.DataFrame or None): DataFrame of association rules with confidence and support.\n",
        "None if no rules meet the threshold.\n",
        "- runtime (float): Execution time in seconds for the algorithm.\n",
        "\n",
        "Notes:\n",
        "- Uses mlxtend.fpgrowth for frequent itemset mining and mlxtend.association_rules for rule generation.\n",
        "- If no frequent itemsets are found, returns (None, None, runtime).\n",
        "- The function prints results in a tabular format using `print_results`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-nkHdfZYuuF"
      },
      "outputs": [],
      "source": [
        "def fpgrowth_algorithm(transaction_df, min_support, min_confidence):\n",
        "    \"\"\"\n",
        "    Run the FP-Growth algorithm using mlxtend to find frequent itemsets and generate association rules.\n",
        "\n",
        "    This function applies the FP-Growth algorithm on a one-hot encoded DataFrame of transactions\n",
        "    to identify frequent itemsets that meet the minimum support threshold. It then generates\n",
        "    association rules from these itemsets that meet the minimum confidence threshold.\n",
        "\n",
        "    Args:\n",
        "        transaction_df (pd.DataFrame): One-hot encoded DataFrame where each column is an item and\n",
        "                                       each row represents a transaction (True if item present).\n",
        "        min_support (float): Minimum support threshold (0 <= min_support <= 1) for an itemset to be considered frequent.\n",
        "        min_confidence (float): Minimum confidence threshold (0 <= min_confidence <= 1) for association rules.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - frequent_itemsets (pd.DataFrame or None): DataFrame of frequent itemsets with support values.\n",
        "                                                        None if no frequent itemsets are found.\n",
        "            - rules (pd.DataFrame or None): DataFrame of association rules with confidence and support.\n",
        "                                            None if no rules meet the threshold.\n",
        "            - runtime (float): Execution time in seconds for the algorithm.\n",
        "\n",
        "    Notes:\n",
        "        - Uses mlxtend.fpgrowth for frequent itemset mining and mlxtend.association_rules for rule generation.\n",
        "        - If no frequent itemsets are found, returns (None, None, runtime).\n",
        "        - The function prints results in a tabular format using `print_results`.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nRunning FP-Growth Algorithm...\")\n",
        "    frequent_itemsets = None\n",
        "    start = time.time()\n",
        "\n",
        "    try:\n",
        "\n",
        "        frequent_itemsets = fpgrowth(transaction_df, min_support=min_support, use_colnames=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error running FP-Tree \\n{e}\")\n",
        "\n",
        "    finally:\n",
        "        runtime = time.time() - start\n",
        "\n",
        "    if frequent_itemsets.empty:\n",
        "        print(\"No frequent itemsets found with FP-Growth.\")\n",
        "        return None, None, runtime\n",
        "\n",
        "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
        "    print(f\"FP-Growth completed in {runtime:.4f} seconds.\\n\")\n",
        "    print_results(\"FP-Growth\", frequent_itemsets, rules)\n",
        "    return frequent_itemsets, rules, runtime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d87ed80e"
      },
      "source": [
        "### How `print_results` works:\n",
        "\n",
        "This function is designed to display the output of the frequent itemset mining algorithms in a clear, easy-to-read table format. It takes the results (frequent itemsets and association rules) from any of the algorithms and uses the `tabulate` library to create well-formatted tables.\n",
        "\n",
        "Here's what it does:\n",
        "\n",
        "1.  **Displays Algorithm Name:** It starts by printing the name of the algorithm whose results are being shown.\n",
        "2.  **Formats Frequent Itemsets:** It takes the frequent itemsets found by an algorithm and puts them into a table. Each row shows an itemset and its corresponding support percentage.\n",
        "3.  **Formats Association Rules:** It takes the association rules generated by an algorithm and presents them in another table. Each row shows a rule (in the format \"items A -> items B\"), its confidence percentage, and its support percentage.\n",
        "4.  **Handles Empty Results:** If an algorithm doesn't find any frequent itemsets or association rules for the given thresholds, the function displays a message indicating that no results were found.\n",
        "\n",
        "Essentially, this function is a utility to make the output of the mining process understandable and presentable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw3bpaSBY8x8"
      },
      "outputs": [],
      "source": [
        "def print_results(algorithm_name, frequent_itemsets, rules):\n",
        "    \"\"\"\n",
        "    Print frequent itemsets and association rules in a tabular format.\n",
        "\n",
        "    This function takes the results from a frequent itemset mining algorithm (either as\n",
        "    a pandas DataFrame or a list of tuples) and prints them neatly using `tabulate`.\n",
        "    Association rules are displayed in the format \"A -> B\" with confidence and support.\n",
        "\n",
        "    Args:\n",
        "        algorithm_name (str): Name of the algorithm (used in the table header).\n",
        "        frequent_itemsets (pd.DataFrame or list of tuples or None): Frequent itemsets with support values.\n",
        "        rules (pd.DataFrame or list of tuples or None): Association rules with confidence and support.\n",
        "\n",
        "    Returns:\n",
        "        None: This function only prints the results; it does not return any value.\n",
        "\n",
        "    Notes:\n",
        "        - If no frequent itemsets or rules are found, appropriate messages are displayed.\n",
        "        - Supports both DataFrame input (from mlxtend) and list-of-tuples input (from custom algorithms).\n",
        "        - Association rules are displayed in the format \"antecedent -> consequent\".\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n=== {algorithm_name} Results ===\")\n",
        "\n",
        "    try:\n",
        "\n",
        "        # --- Frequent Itemsets ---\n",
        "        print(\"\\nFrequent Itemsets:\")\n",
        "        if isinstance(frequent_itemsets, pd.DataFrame):\n",
        "            itemset_data = [\n",
        "                [\", \".join(list(row[\"itemsets\"])), f\"{row['support']*100:.2f}%\"]\n",
        "                for _, row in frequent_itemsets.iterrows()\n",
        "            ]\n",
        "        elif frequent_itemsets:\n",
        "            itemset_data = [\n",
        "                [\", \".join(itemset), f\"{support*100:.2f}%\"]\n",
        "                for itemset, support in frequent_itemsets\n",
        "            ]\n",
        "        else:\n",
        "            itemset_data = [[\"No frequent itemsets found\", \"\"]]\n",
        "\n",
        "        print(tabulate(itemset_data, headers=[\"Itemset\", \"Support\"], tablefmt=\"fancy_grid\"))\n",
        "\n",
        "        # --- Association Rules ---\n",
        "        print(\"\\nAssociation Rules:\")\n",
        "        if isinstance(rules, pd.DataFrame) and not rules.empty:\n",
        "            rule_data = [\n",
        "                [f\"{', '.join(list(rule['antecedents']))} -> {', '.join(list(rule['consequents']))}\",\n",
        "                f\"{rule['confidence']*100:.2f}%\",\n",
        "                f\"{rule['support']*100:.2f}%\"]\n",
        "                for _, rule in rules.iterrows()\n",
        "            ]\n",
        "        elif rules is not None and len(rules) > 0:\n",
        "            rule_data = [\n",
        "                [f\"{', '.join(antecedent)} -> {', '.join(consequent)}\",\n",
        "                f\"{confidence*100:.2f}%\",\n",
        "                f\"{support*100:.2f}%\"]\n",
        "                for antecedent, consequent, confidence, support in rules\n",
        "            ]\n",
        "        else:\n",
        "            rule_data = [[\"No association rules found\", \"\", \"\"]]\n",
        "\n",
        "        print(tabulate(rule_data, headers=[\"Rule\", \"Confidence\", \"Support\"], tablefmt=\"fancy_grid\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error printing results \\n{e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d23507a"
      },
      "source": [
        "### How `main` works:\n",
        "\n",
        "This function serves as the primary control center for running the frequent itemset mining analysis. It orchestrates the entire process by:\n",
        "\n",
        "1.  **Presenting Store Options:** It displays a list of available stores with corresponding transaction and itemset files.\n",
        "2.  **Getting User Input:** It prompts the user to select a store and enter the desired minimum support and confidence thresholds (as percentages).\n",
        "3.  **Loading Data:** It calls `load_transaction_data` to load the selected transaction and itemset files.\n",
        "4.  **Preparing Data for Algorithms:** It uses `prepare_transaction_dataframe` to convert the raw transactions into a format suitable for the Apriori and FP-Growth algorithms.\n",
        "5.  **Running Algorithms:** It executes the `brute_force_algorithm`, `apriori_algorithm`, and `fpgrowth_algorithm` with the loaded data and user-defined thresholds.\n",
        "6.  **Displaying Results:** For each algorithm, it uses `print_results` to display the found frequent itemsets and association rules in a clear, tabular format.\n",
        "7.  **Comparing Performance:** It tracks and displays the execution time for each algorithm.\n",
        "8.  **Identifying Fastest Algorithm:** Finally, it determines and announces which algorithm completed the task the fastest.\n",
        "\n",
        "In essence, the `main` function is the entry point that brings all the other functions together to perform the itemset mining analysis based on user interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7RF0TwXaCPU",
        "outputId": "38e77dc3-4b2a-474b-a0dd-b11ae4faa140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Welcome to ruleFinder!\n",
            "\n",
            "Available stores:\n",
            "1. Amazon\n",
            "2. Bestbuy\n",
            "3. Shoprite\n",
            "4. K-mart\n",
            "5. Nike\n",
            "Enter the number of the store you want to analyze: 1\n",
            "Enter the minimum support (as % between 1 and 100): 59\n",
            "Enter the minimum confidence (as % between 1 and 100): 59\n",
            "\n",
            "Analyzing store: Amazon\n",
            "------------------------------------------------------------\n",
            "\n",
            "Running Brute Force Algorithm...\n",
            "Brute Force completed in 0.0038 seconds.\n",
            "\n",
            "\n",
            "=== Brute Force Results ===\n",
            "\n",
            "Frequent Itemsets:\n",
            "╒═════════════════════════════════════════╤═══════════╕\n",
            "│ Itemset                                 │ Support   │\n",
            "╞═════════════════════════════════════════╪═══════════╡\n",
            "│ Android Programming: The Big Nerd Ranch │ 65.00%    │\n",
            "├─────────────────────────────────────────┼───────────┤\n",
            "│ Java For Dummies                        │ 65.00%    │\n",
            "╘═════════════════════════════════════════╧═══════════╛\n",
            "\n",
            "Association Rules:\n",
            "╒════════════════════════════╤══════════════╤═══════════╕\n",
            "│ Rule                       │ Confidence   │ Support   │\n",
            "╞════════════════════════════╪══════════════╪═══════════╡\n",
            "│ No association rules found │              │           │\n",
            "╘════════════════════════════╧══════════════╧═══════════╛\n",
            "\n",
            "Running Apriori Algorithm...\n",
            "Apriori completed in 0.0099 seconds.\n",
            "\n",
            "\n",
            "=== Apriori Results ===\n",
            "\n",
            "Frequent Itemsets:\n",
            "╒═════════════════════════════════════════╤═══════════╕\n",
            "│ Itemset                                 │ Support   │\n",
            "╞═════════════════════════════════════════╪═══════════╡\n",
            "│ Android Programming: The Big Nerd Ranch │ 65.00%    │\n",
            "├─────────────────────────────────────────┼───────────┤\n",
            "│ Java For Dummies                        │ 65.00%    │\n",
            "╘═════════════════════════════════════════╧═══════════╛\n",
            "\n",
            "Association Rules:\n",
            "╒════════════════════════════╤══════════════╤═══════════╕\n",
            "│ Rule                       │ Confidence   │ Support   │\n",
            "╞════════════════════════════╪══════════════╪═══════════╡\n",
            "│ No association rules found │              │           │\n",
            "╘════════════════════════════╧══════════════╧═══════════╛\n",
            "\n",
            "Running FP-Growth Algorithm...\n",
            "FP-Growth completed in 0.0092 seconds.\n",
            "\n",
            "\n",
            "=== FP-Growth Results ===\n",
            "\n",
            "Frequent Itemsets:\n",
            "╒═════════════════════════════════════════╤═══════════╕\n",
            "│ Itemset                                 │ Support   │\n",
            "╞═════════════════════════════════════════╪═══════════╡\n",
            "│ Java For Dummies                        │ 65.00%    │\n",
            "├─────────────────────────────────────────┼───────────┤\n",
            "│ Android Programming: The Big Nerd Ranch │ 65.00%    │\n",
            "╘═════════════════════════════════════════╧═══════════╛\n",
            "\n",
            "Association Rules:\n",
            "╒════════════════════════════╤══════════════╤═══════════╕\n",
            "│ Rule                       │ Confidence   │ Support   │\n",
            "╞════════════════════════════╪══════════════╪═══════════╡\n",
            "│ No association rules found │              │           │\n",
            "╘════════════════════════════╧══════════════╧═══════════╛\n",
            "\n",
            "Execution Times (seconds):\n",
            "+-------------+------------+\n",
            "| Algorithm   |   Time (s) |\n",
            "+=============+============+\n",
            "| Brute Force |     0.0038 |\n",
            "+-------------+------------+\n",
            "| Apriori     |     0.0099 |\n",
            "+-------------+------------+\n",
            "| FP-Growth   |     0.0092 |\n",
            "+-------------+------------+\n",
            "\n",
            " The fastest algorithm is: Brute Force (0.0038 seconds)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main entry point to compare Brute Force, Apriori, and FP-Growth algorithms on transaction data.\n",
        "\n",
        "    This function allows the user to select a store, load its transaction data, set minimum\n",
        "    support and confidence thresholds, and run three frequent itemset mining algorithms.\n",
        "    It prints the frequent itemsets, association rules, execution times, and identifies\n",
        "    the fastest algorithm.\n",
        "\n",
        "    Args:\n",
        "        None: All inputs are collected via user prompts.\n",
        "\n",
        "    Returns:\n",
        "        None: This function only prints results; it does not return any value.\n",
        "\n",
        "    Notes:\n",
        "        - Uses `load_transaction_data` to read transactions and item mappings from CSV files.\n",
        "        - Converts transactions into a one-hot encoded DataFrame for mlxtend algorithms.\n",
        "        - Runs `brute_force_algorithm`, `apriori_algorithm`, and `fpgrowth_algorithm`.\n",
        "        - Prints results for each algorithm using `print_results`.\n",
        "        - Displays execution times and highlights the fastest algorithm.\n",
        "    \"\"\"\n",
        "\n",
        "    stores = {\n",
        "        \"1\": (\"Amazon\", \"Amazon_Transaction.csv\", \"Amazon_Itemset.csv\"),\n",
        "        \"2\": (\"Bestbuy\", \"Bestbuy_Transaction.csv\", \"Bestbuy_Itemset.csv\"),\n",
        "        \"3\": (\"Shoprite\", \"Shoprite_Transaction.csv\", \"Shoprite_Itemset.csv\"),\n",
        "        \"4\": (\"K-mart\", \"K_mart_Transaction.csv\", \"K_mart_Itemset.csv\"),\n",
        "        \"5\": (\"Nike\", \"Nike_Transaction.csv\", \"Nike_Itemset.csv\")\n",
        "    }\n",
        "\n",
        "    print(\"\\nWelcome to ruleFinder!\")\n",
        "    print(\"\\nAvailable stores:\")\n",
        "    for key, (store_name, _, _) in stores.items():\n",
        "        print(f\"{key}. {store_name}\")\n",
        "\n",
        "    # --- Store selection ---\n",
        "    while True:\n",
        "        choice = input(\"Enter the number of the store you want to analyze: \").strip()\n",
        "        if choice in stores:\n",
        "            store_name, transaction_file, itemset_file = stores[choice]\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter a number between 1 and 5.\")\n",
        "\n",
        "    # --- Load data ---\n",
        "    transaction_file = \"../data/\" + transaction_file\n",
        "    itemset_file = \"../data/\" + itemset_file\n",
        "    transactions, item_map = load_transaction_data(transaction_file, itemset_file)\n",
        "    if not transactions:\n",
        "        print(\"No valid transactions found. Please check your CSV files.\")\n",
        "        return\n",
        "\n",
        "    # --- User input for thresholds ---\n",
        "    while True:\n",
        "        try:\n",
        "            min_support = float(input(\"Enter the minimum support (as % between 1 and 100): \"))\n",
        "            if 1 <= min_support <= 100:\n",
        "                min_support /= 100\n",
        "                break\n",
        "            print(\"Please enter a value between 1 and 100.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Enter a numeric value.\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            min_confidence = float(input(\"Enter the minimum confidence (as % between 1 and 100): \"))\n",
        "            if 1 <= min_confidence <= 100:\n",
        "                min_confidence /= 100\n",
        "                break\n",
        "            print(\"Please enter a value between 1 and 100.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Enter a numeric value.\")\n",
        "\n",
        "    # --- Prepare DataFrame for mlxtend algorithms ---\n",
        "    transaction_df = prepare_transaction_dataframe(transactions)\n",
        "\n",
        "    print(f\"\\nAnalyzing store: {store_name}\\n{'-'*60}\")\n",
        "\n",
        "    # --- Run algorithms ---\n",
        "    bf_itemsets, bf_rules, bf_time = brute_force_algorithm(transactions, min_support, min_confidence)\n",
        "    apr_itemsets, apr_rules, apr_time = apriori_algorithm(transaction_df, min_support, min_confidence)\n",
        "    fp_itemsets, fp_rules, fp_time = fpgrowth_algorithm(transaction_df, min_support, min_confidence)\n",
        "\n",
        "\n",
        "    results_table = [\n",
        "        [\"Brute Force\", f\"{bf_time:.4f}\"],\n",
        "        [\"Apriori\", f\"{apr_time:.4f}\"],\n",
        "        [\"FP-Growth\", f\"{fp_time:.4f}\"]\n",
        "    ]\n",
        "\n",
        "    print(\"\\nExecution Times (seconds):\")\n",
        "    print(tabulate(results_table, headers=[\"Algorithm\", \"Time (s)\"], tablefmt=\"grid\"))\n",
        "\n",
        "    # --- Determine fastest algorithm ---\n",
        "    times = {\n",
        "        \"Brute Force\": bf_time,\n",
        "        \"Apriori\": apr_time,\n",
        "        \"FP-Growth\": fp_time\n",
        "    }\n",
        "    fastest = min(times, key=times.get)\n",
        "    print(f\"\\n The fastest algorithm is: {fastest} ({times[fastest]:.4f} seconds)\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}